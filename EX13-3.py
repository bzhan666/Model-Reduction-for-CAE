# -*- coding: utf-8 -*-
"""
ä¼˜åŒ–çš„æµä½“æ•°æ®å¤„ç†ä»£ç  (EX13)
Created on Thu Sep 25 11:03:22 2025

ä¸»è¦ä¼˜åŒ–ï¼š
1. é¢å‘å¯¹è±¡è®¾è®¡ï¼Œæé«˜ä»£ç å¯ç»´æŠ¤æ€§
2. é”™è¯¯å¤„ç†å’Œå‚æ•°éªŒè¯
3. æ€§èƒ½ä¼˜åŒ–å’Œå†…å­˜ç®¡ç†
4. æ›´å¥½çš„å¯è§†åŒ–æ•ˆæœ
5. æ—¥å¿—å’Œè¿›åº¦æ˜¾ç¤º

@author: bzhan666
"""

import numpy as np
import matplotlib
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
import os
from pathlib import Path
import warnings
from typing import Tuple, Optional, Union
import time
from contextlib import contextmanager

# ===== å¼ºåˆ¶ä¸­æ–‡å­—ä½“è®¾ç½® =====
def setup_chinese_font_force():
    """å¼ºåˆ¶è®¾ç½®ä¸­æ–‡å­—ä½“"""
    # æ–¹æ³•1ï¼šæ¸…é™¤matplotlibç¼“å­˜
    try:
        matplotlib.font_manager._rebuild()
    except:
        pass
    
    # æ–¹æ³•2ï¼šå¤šé‡å­—ä½“è®¾ç½®
    matplotlib.rcParams['font.family'] = 'sans-serif'
    matplotlib.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'DejaVu Sans']
    matplotlib.rcParams['axes.unicode_minus'] = False
    
    # æ–¹æ³•3ï¼šå¼ºåˆ¶è®¾ç½®å­—ä½“å±æ€§
    plt.rcParams.update({
        'font.family': 'sans-serif',
        'font.sans-serif': ['SimHei', 'Microsoft YaHei'],
        'axes.unicode_minus': False,
        'figure.autolayout': True
    })
    
    print("âœ… ä¸­æ–‡å­—ä½“è®¾ç½®å®Œæˆ")

# æ‰§è¡Œå­—ä½“è®¾ç½®
setup_chinese_font_force()

# è®¾ç½®å›¾è¡¨æ ·å¼
try:
    plt.style.use('seaborn-v0_8')
except:
    try:
        plt.style.use('seaborn')
    except:
        plt.style.use('default')

@contextmanager
def timer(description: str):
    """è®¡æ—¶å™¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
    start = time.time()
    print(f"å¼€å§‹ {description}...")
    yield
    end = time.time()
    print(f"å®Œæˆ {description} - è€—æ—¶: {end - start:.2f}ç§’")

class FluentDataSimulator:
    """Fluentæ•°æ®æ¨¡æ‹Ÿå™¨ç±»"""
    
    def __init__(self, nx: int = 80, ny: int = 40, nt: int = 100):
        """
        åˆå§‹åŒ–æ¨¡æ‹Ÿå™¨
        
        Args:
            nx: xæ–¹å‘ç½‘æ ¼ç‚¹æ•°
            ny: yæ–¹å‘ç½‘æ ¼ç‚¹æ•°  
            nt: æ—¶é—´æ­¥æ•°
        """
        self.nx = max(10, nx)  # å‚æ•°éªŒè¯
        self.ny = max(10, ny)
        self.nt = max(1, nt)
        
        # åˆ›å»ºè®¡ç®—ç½‘æ ¼
        self.x = np.linspace(-2, 14, self.nx)
        self.y = np.linspace(-4, 4, self.ny)
        self.X, self.Y = np.meshgrid(self.x, self.y)
        
        print(f"åˆå§‹åŒ–æ¨¡æ‹Ÿå™¨ - ç½‘æ ¼å°ºå¯¸: {self.nx}Ã—{self.ny}, æ—¶é—´æ­¥: {self.nt}")

    def generate_karman_vortex_data(self, output_path: Union[str, Path] = './fluent_data') -> Tuple[int, int, int]:
        """
        ç”Ÿæˆå¡é—¨æ¶¡è¡—æµåœºæ•°æ®
        
        Args:
            output_path: è¾“å‡ºè·¯å¾„
            
        Returns:
            (nx, ny, nt): ç½‘æ ¼å’Œæ—¶é—´å‚æ•°
        """
        output_path = Path(output_path)
        output_path.mkdir(parents=True, exist_ok=True)
        
        print(f"æ­£åœ¨ç”Ÿæˆå¡é—¨æ¶¡è¡—æ•°æ®åˆ°: {output_path}")
        
        with timer("å¡é—¨æ¶¡è¡—æ•°æ®ç”Ÿæˆ"):
            # é¢„è®¡ç®—ä¸€äº›å¸¸é‡ä»¥æé«˜æ€§èƒ½
            dt = 0.1
            vortex_strength = 0.5
            decay_rate = 0.05
            
            for i in range(self.nt):
                t = i * dt
                
                # æ”¹è¿›çš„æ¶¡è¡—ç‰©ç†æ¨¡å‹
                u_velocity = self._compute_velocity_field(t, vortex_strength, decay_rate)
                
                # ä¿å­˜æ•°æ®æ–‡ä»¶
                filename = output_path / f'flow_t_{i:04d}.dat'
                self._save_fluent_format(filename, self.X, self.Y, u_velocity, t)
                
                # è¿›åº¦æ˜¾ç¤º
                if i % max(1, self.nt // 10) == 0:
                    progress = (i + 1) / self.nt * 100
                    print(f"  è¿›åº¦: {progress:.1f}% ({i+1}/{self.nt})")
        
        print("æ•°æ®ç”Ÿæˆå®Œæˆ!")
        return self.nx, self.ny, self.nt

    def _compute_velocity_field(self, t: float, strength: float, decay: float) -> np.ndarray:
        """
        è®¡ç®—æ›´çœŸå®çš„é€Ÿåº¦åœº
        
        Args:
            t: å½“å‰æ—¶é—´
            strength: æ¶¡å¼ºåº¦
            decay: è¡°å‡ç‡
        """
        # åŸºç¡€æµé€Ÿ
        u_base = np.ones_like(self.X)
        
        # åœ†æŸ±ä½“å‡ ä½• (å¯é€‰)
        cylinder_x, cylinder_y = 2.0, 0.0
        cylinder_radius = 0.5
        
        # æ¶¡è„±è½å‚æ•°
        vortex_frequency = 0.2
        shedding_amplitude = 1.2
        downstream_positions = [4, 7, 10, 13]  # å¤šä¸ªæ¶¡çš„ä¸‹æ¸¸ä½ç½®
        
        # ç”Ÿæˆäº¤æ›¿æ¶¡
        for i, x_pos in enumerate(downstream_positions):
            phase = vortex_frequency * t + i * np.pi  # äº¤æ›¿ç›¸ä½
            
            # ä¸Šæ¶¡
            y_upper = shedding_amplitude * np.sin(phase)
            vortex_upper = strength * np.exp(
                -(((self.X - x_pos)**2 + (self.Y - y_upper)**2) * 
                  (1 + decay * (self.X - cylinder_x)))
            )
            
            # ä¸‹æ¶¡ (ç›¸ä½å·®Ï€)
            y_lower = -shedding_amplitude * np.sin(phase + np.pi)
            vortex_lower = -strength * np.exp(
                -(((self.X - x_pos)**2 + (self.Y - y_lower)**2) * 
                  (1 + decay * (self.X - cylinder_x)))
            )
            
            u_base += vortex_upper + vortex_lower
        
        # æ·»åŠ è¾¹ç•Œæ¡ä»¶å’Œå™ªå£°
        mask = (self.X - cylinder_x)**2 + (self.Y - cylinder_y)**2 <= cylinder_radius**2
        u_base[mask] = 0  # åœ†æŸ±å†…éƒ¨æ— æ»‘ç§»è¾¹ç•Œæ¡ä»¶
        
        # æ·»åŠ å°æ‰°åŠ¨æ¨¡æ‹Ÿæ¹æµ
        if t > 2.0:  # åˆå§‹é˜¶æ®µä¿æŒç¨³å®š
            noise = 0.01 * np.random.normal(size=u_base.shape)
            u_base += noise
            
        return u_base

    @staticmethod
    def _save_fluent_format(filename: Path, X: np.ndarray, Y: np.ndarray, 
                           U: np.ndarray, time: float):
        """ä¿å­˜Fluentæ ¼å¼æ•°æ®æ–‡ä»¶"""
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                f.write("VARIABLES = X, Y, U\n")
                f.write(f"ZONE T=time_{time:.2f}\n")
                
                # å‘é‡åŒ–æ•°æ®å†™å…¥
                data_array = np.column_stack([X.ravel(), Y.ravel(), U.ravel()])
                np.savetxt(f, data_array, fmt='%.6f')
        except IOError as e:
            raise IOError(f"æ— æ³•ä¿å­˜æ–‡ä»¶ {filename}: {e}")

class FluentDataLoader:
    """Fluentæ•°æ®åŠ è½½å™¨ç±»"""
    
    def __init__(self, data_path: Union[str, Path]):
        """
        åˆå§‹åŒ–åŠ è½½å™¨
        
        Args:
            data_path: æ•°æ®æ–‡ä»¶è·¯å¾„
        """
        self.data_path = Path(data_path)
        self._validate_path()
        
    def _validate_path(self):
        """éªŒè¯æ•°æ®è·¯å¾„"""
        if not self.data_path.exists():
            raise FileNotFoundError(f"æ•°æ®è·¯å¾„ä¸å­˜åœ¨: {self.data_path}")
        if not self.data_path.is_dir():
            raise NotADirectoryError(f"è·¯å¾„ä¸æ˜¯ç›®å½•: {self.data_path}")

    def load_snapshot_matrix(self, num_snapshots: int, 
                           field_index: int = 2) -> Tuple[np.ndarray, np.ndarray]:
        """
        åŠ è½½å¹¶ç»„è£…å¿«ç…§çŸ©é˜µ
        
        Args:
            num_snapshots: å¿«ç…§æ•°é‡
            field_index: å­—æ®µç´¢å¼• (0:X, 1:Y, 2:U)
            
        Returns:
            (snapshot_matrix, coordinates): å¿«ç…§çŸ©é˜µå’Œåæ ‡ä¿¡æ¯
        """
        if not isinstance(num_snapshots, int) or num_snapshots <= 0:
            raise ValueError("å¿«ç…§æ•°é‡å¿…é¡»æ˜¯æ­£æ•´æ•°")
        if not 0 <= field_index <= 2:
            raise ValueError("å­—æ®µç´¢å¼•å¿…é¡»åœ¨0-2ä¹‹é—´")
            
        print(f"å¼€å§‹åŠ è½½ {num_snapshots} ä¸ªå¿«ç…§...")
        
        # ä»ç¬¬ä¸€ä¸ªæ–‡ä»¶è·å–ç½‘æ ¼ä¿¡æ¯
        first_file = self.data_path / 'flow_t_0000.dat'
        if not first_file.exists():
            raise FileNotFoundError(f"ç¬¬ä¸€ä¸ªæ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {first_file}")
        
        with timer("ç½‘æ ¼ä¿¡æ¯è¯»å–"):
            grid_info = self._load_single_file(first_file)
            spatial_points = grid_info.shape[0]
            coordinates = grid_info[:, :2].copy()
        
        # é¢„åˆ†é…å†…å­˜ - ä½¿ç”¨float32èŠ‚çœå†…å­˜
        snapshot_matrix = np.zeros((spatial_points, num_snapshots), dtype=np.float32)
        
        with timer("æ‰¹é‡æ•°æ®åŠ è½½"):
            successful_loads = 0
            for i in range(num_snapshots):
                filename = self.data_path / f'flow_t_{i:04d}.dat'
                
                try:
                    data = self._load_single_file(filename)
                    snapshot_matrix[:, i] = data[:, field_index].astype(np.float32)
                    successful_loads += 1
                except (FileNotFoundError, ValueError) as e:
                    warnings.warn(f"è·³è¿‡æ–‡ä»¶ {filename}: {e}")
                    continue
                
                # è¿›åº¦æ˜¾ç¤º
                if i % max(1, num_snapshots // 10) == 0:
                    progress = (i + 1) / num_snapshots * 100
                    print(f"  åŠ è½½è¿›åº¦: {progress:.1f}% ({i+1}/{num_snapshots})")
        
        if successful_loads == 0:
            raise RuntimeError("æ²¡æœ‰æˆåŠŸåŠ è½½ä»»ä½•æ•°æ®æ–‡ä»¶")
        
        print(f"æˆåŠŸåŠ è½½ {successful_loads}/{num_snapshots} ä¸ªå¿«ç…§")
        print(f"å¿«ç…§çŸ©é˜µå°ºå¯¸: {snapshot_matrix.shape}")
        
        return snapshot_matrix, coordinates

    @staticmethod
    def _load_single_file(filename: Path) -> np.ndarray:
        """åŠ è½½å•ä¸ªæ•°æ®æ–‡ä»¶"""
        try:
            return np.loadtxt(filename, skiprows=2)
        except (OSError, ValueError) as e:
            raise ValueError(f"æ–‡ä»¶æ ¼å¼é”™è¯¯: {filename}") from e

class DataProcessor:
    """æ•°æ®å¤„ç†å™¨ç±»"""
    
    @staticmethod
    def compute_mean_subtraction(snapshot_matrix: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
        """
        è®¡ç®—å‡å€¼å‡æ³•é¢„å¤„ç†
        
        Args:
            snapshot_matrix: åŸå§‹å¿«ç…§çŸ©é˜µ
            
        Returns:
            (fluctuation_matrix, mean_field): è„‰åŠ¨çŸ©é˜µå’Œæ—¶é—´å¹³å‡åœº
        """
        if snapshot_matrix.size == 0:
            raise ValueError("è¾“å…¥çŸ©é˜µä¸ºç©º")
            
        print("æ‰§è¡Œæ•°æ®é¢„å¤„ç†...")
        
        with timer("æ—¶é—´å¹³å‡è®¡ç®—"):
            # è®¡ç®—æ—¶é—´å¹³å‡åœº
            mean_field = np.mean(snapshot_matrix, axis=1)
            
        with timer("è„‰åŠ¨åœºè®¡ç®—"):
            # è®¡ç®—è„‰åŠ¨åœº (åŸåœºå‡å»å¹³å‡åœº)
            fluctuation_matrix = snapshot_matrix - mean_field[:, np.newaxis]
        
        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        rms_fluctuation = np.sqrt(np.mean(fluctuation_matrix**2))
        print(f"è„‰åŠ¨åœºRMS: {rms_fluctuation:.4f}")
        
        return fluctuation_matrix, mean_field

    @staticmethod
    def compute_statistics(data: np.ndarray) -> dict:
        """è®¡ç®—æ•°æ®ç»Ÿè®¡ä¿¡æ¯"""
        return {
            'mean': np.mean(data),
            'std': np.std(data),
            'min': np.min(data),
            'max': np.max(data),
            'rms': np.sqrt(np.mean(data**2))
        }

class FlowFieldVisualizer:
    """æµåœºå¯è§†åŒ–å™¨ç±»"""
    
    def __init__(self, figsize: Tuple[int, int] = (18, 5)):
        self.figsize = figsize
        
    def plot_flow_fields(self, fields_data: dict, coordinates: np.ndarray, 
                        nx: int, ny: int, save_path: Optional[str] = None):
        """
        ç»˜åˆ¶å¤šä¸ªæµåœºå¯¹æ¯”å›¾
        
        Args:
            fields_data: åŒ…å«ä¸åŒæµåœºæ•°æ®çš„å­—å…¸
            coordinates: ç½‘æ ¼åæ ‡
            nx, ny: ç½‘æ ¼å°ºå¯¸
            save_path: ä¿å­˜è·¯å¾„ï¼ˆå¯é€‰ï¼‰
        """
        # å†æ¬¡ç¡®ä¿å­—ä½“è®¾ç½®
        plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei']
        plt.rcParams['axes.unicode_minus'] = False
        
        num_fields = len(fields_data)
        if num_fields == 0:
            raise ValueError("æ²¡æœ‰æä¾›æµåœºæ•°æ®")
            
        fig, axes = plt.subplots(1, num_fields, figsize=(6*num_fields, 5))
        if num_fields == 1:
            axes = [axes]
        
        # é‡æ„ç½‘æ ¼
        grid_x = coordinates[:, 0].reshape(ny, nx)
        grid_y = coordinates[:, 1].reshape(ny, nx)
        
        for idx, (title, field_data) in enumerate(fields_data.items()):
            field_2d = field_data.reshape(ny, nx)
            
            # åˆ›å»ºç­‰é«˜çº¿å›¾
            if 'è„‰åŠ¨' in title or 'fluctuation' in title.lower():
                # è„‰åŠ¨åœºä½¿ç”¨å¯¹ç§°é¢œè‰²æ˜ å°„
                vmax = np.abs(field_2d).max()
                levels = np.linspace(-vmax, vmax, 50)
                contour = axes[idx].contourf(grid_x, grid_y, field_2d, 
                                           levels=levels, cmap='RdBu_r')
            else:
                # å…¶ä»–åœºä½¿ç”¨å¸¸è§„é¢œè‰²æ˜ å°„
                contour = axes[idx].contourf(grid_x, grid_y, field_2d, 
                                           levels=50, cmap='viridis')
            
            # è®¾ç½®æ ‡é¢˜å’Œæ ‡ç­¾ - æ˜¾å¼è®¾ç½®å­—ä½“
            axes[idx].set_title(title, fontsize=14, fontweight='bold', 
                              fontproperties='SimHei')
            axes[idx].set_xlabel('Xåæ ‡', fontsize=12, fontproperties='SimHei')
            axes[idx].set_ylabel('Yåæ ‡', fontsize=12, fontproperties='SimHei')
            axes[idx].set_aspect('equal')
            
            # æ·»åŠ é¢œè‰²æ¡
            cbar = plt.colorbar(contour, ax=axes[idx])
            cbar.ax.tick_params(labelsize=10)
            
            # æ·»åŠ ç½‘æ ¼
            axes[idx].grid(True, alpha=0.3, linestyle='--')
        
        plt.suptitle('æµåœºå¯¹æ¯”åˆ†æ', fontsize=16, fontweight='bold',
                    fontproperties='SimHei')
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"å›¾åƒå·²ä¿å­˜åˆ°: {save_path}")
        
        plt.show()

    def plot_statistics_summary(self, data_dict: dict):
        """ç»˜åˆ¶æ•°æ®ç»Ÿè®¡æ‘˜è¦"""
        # å†æ¬¡ç¡®ä¿å­—ä½“è®¾ç½®
        plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei']
        plt.rcParams['axes.unicode_minus'] = False
        
        fig, axes = plt.subplots(2, 2, figsize=(12, 8))
        
        field_names = list(data_dict.keys())
        statistics = [DataProcessor.compute_statistics(data) for data in data_dict.values()]
        
        # å‡å€¼å¯¹æ¯”
        means = [stat['mean'] for stat in statistics]
        bars1 = axes[0, 0].bar(field_names, means)
        axes[0, 0].set_title('æ—¶é—´å¹³å‡å€¼å¯¹æ¯”', fontproperties='SimHei')
        axes[0, 0].set_ylabel('å¹³å‡å€¼', fontproperties='SimHei')
        axes[0, 0].tick_params(axis='x', rotation=45)
        # è®¾ç½®xè½´æ ‡ç­¾å­—ä½“
        for label in axes[0, 0].get_xticklabels():
            label.set_fontproperties('SimHei')
        
        # æ ‡å‡†å·®å¯¹æ¯”
        stds = [stat['std'] for stat in statistics]
        bars2 = axes[0, 1].bar(field_names, stds, color='orange')
        axes[0, 1].set_title('æ ‡å‡†å·®å¯¹æ¯”', fontproperties='SimHei')
        axes[0, 1].set_ylabel('æ ‡å‡†å·®', fontproperties='SimHei')
        axes[0, 1].tick_params(axis='x', rotation=45)
        for label in axes[0, 1].get_xticklabels():
            label.set_fontproperties('SimHei')
        
        # æå€¼å¯¹æ¯”
        mins = [stat['min'] for stat in statistics]
        maxs = [stat['max'] for stat in statistics]
        x_pos = np.arange(len(field_names))
        bars3 = axes[1, 0].bar(x_pos, maxs, label='æœ€å¤§å€¼', alpha=0.7)
        bars4 = axes[1, 0].bar(x_pos, mins, label='æœ€å°å€¼', alpha=0.7)
        axes[1, 0].set_title('æå€¼å¯¹æ¯”', fontproperties='SimHei')
        axes[1, 0].set_ylabel('æ•°å€¼', fontproperties='SimHei')
        axes[1, 0].set_xticks(x_pos)
        axes[1, 0].set_xticklabels(field_names, rotation=45)
        for label in axes[1, 0].get_xticklabels():
            label.set_fontproperties('SimHei')
        # è®¾ç½®å›¾ä¾‹å­—ä½“
        legend = axes[1, 0].legend(prop='SimHei')
        
        # RMSå¯¹æ¯”
        rms_values = [stat['rms'] for stat in statistics]
        bars5 = axes[1, 1].bar(field_names, rms_values, color='green')
        axes[1, 1].set_title('RMSå€¼å¯¹æ¯”', fontproperties='SimHei')
        axes[1, 1].set_ylabel('RMS', fontproperties='SimHei')
        axes[1, 1].tick_params(axis='x', rotation=45)
        for label in axes[1, 1].get_xticklabels():
            label.set_fontproperties('SimHei')
        
        plt.tight_layout()
        plt.show()

def run_complete_analysis(data_path: str = './fluent_data', 
                         nx: int = 80, ny: int = 40, nt: int = 100,
                         regenerate_data: bool = True) -> dict:
    """
    è¿è¡Œå®Œæ•´çš„æµä½“æ•°æ®åˆ†ææµæ°´çº¿
    
    Args:
        data_path: æ•°æ®è·¯å¾„
        nx, ny, nt: ç½‘æ ¼å’Œæ—¶é—´å‚æ•°
        regenerate_data: æ˜¯å¦é‡æ–°ç”Ÿæˆæ•°æ®
        
    Returns:
        åŒ…å«æ‰€æœ‰åˆ†æç»“æœçš„å­—å…¸
    """
    print("=" * 50)
    print("æµä½“æ•°æ®å¤„ç†ä¸å¯è§†åŒ–åˆ†æç¨‹åº")
    print("=" * 50)
    
    results = {}
    
    try:
        # æ­¥éª¤1: æ•°æ®ç”Ÿæˆ
        if regenerate_data:
            print("\nğŸ“Š æ­¥éª¤1: æ•°æ®ç”Ÿæˆ")
            simulator = FluentDataSimulator(nx=nx, ny=ny, nt=nt)
            nx, ny, nt = simulator.generate_karman_vortex_data(output_path=data_path)
            results.update({'nx': nx, 'ny': ny, 'nt': nt})
        
        # æ­¥éª¤2: æ•°æ®åŠ è½½
        print("\nğŸ“ æ­¥éª¤2: æ•°æ®åŠ è½½")
        loader = FluentDataLoader(data_path)
        snapshot_matrix, coordinates = loader.load_snapshot_matrix(num_snapshots=nt)
        results.update({
            'snapshot_matrix': snapshot_matrix,
            'coordinates': coordinates
        })
        
        # æ­¥éª¤3: æ•°æ®é¢„å¤„ç†
        print("\nâš™ï¸ æ­¥éª¤3: æ•°æ®é¢„å¤„ç†")
        processor = DataProcessor()
        fluctuation_matrix, mean_field = processor.compute_mean_subtraction(snapshot_matrix)
        results.update({
            'fluctuation_matrix': fluctuation_matrix,
            'mean_field': mean_field
        })
        
        # æ­¥éª¤4: å¯è§†åŒ–åˆ†æ
        print("\nğŸ“ˆ æ­¥éª¤4: å¯è§†åŒ–åˆ†æ")
        visualizer = FlowFieldVisualizer()
        
        # æµåœºå¯¹æ¯”
        flow_fields = {
            'æ—¶é—´å¹³å‡æµåœº': mean_field,
            'ç¬æ—¶æµåœº': snapshot_matrix[:, -1],
            'ç¬æ—¶è„‰åŠ¨æµåœº': fluctuation_matrix[:, -1]
        }
        visualizer.plot_flow_fields(flow_fields, coordinates, nx, ny)
        
        # ç»Ÿè®¡åˆ†æ
        visualizer.plot_statistics_summary(flow_fields)
        
        print("\nâœ… åˆ†æå®Œæˆ!")
        print(f"ğŸ“Š æ•°æ®çŸ©é˜µå°ºå¯¸: {snapshot_matrix.shape}")
        print(f"ğŸ“ ç©ºé—´ç‚¹æ•°: {coordinates.shape[0]}")
        print(f"â±ï¸ æ—¶é—´æ­¥æ•°: {nt}")
        
        return results
        
    except Exception as e:
        print(f"\nâŒ ç¨‹åºæ‰§è¡Œé”™è¯¯: {e}")
        raise

if __name__ == "__main__":
    # è¿è¡Œå®Œæ•´åˆ†æ
    analysis_results = run_complete_analysis(
        data_path='./fluent_data',
        nx=80, 
        ny=40, 
        nt=100,
        regenerate_data=True
    )
    
    print("\n" + "=" * 50)
    print("åˆ†æç»“æœå·²ä¿å­˜åœ¨ analysis_results å˜é‡ä¸­")
    print("=" * 50)